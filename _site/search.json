[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Haiyang‚Äôs Tech Portfolio",
    "section": "",
    "text": "Hello! I‚Äôm Xu Haiyang, a Computer Science graduate specializing in Cybersecurity & Cyber-Physical Systems. This website serves as a portfolio to showcase my projects, research, and technical knowledge in IoT, Cybersecurity, AWS Cloud, and AI.\n\n\n\nEducation:\n\nSingapore Management University (Aug 2021 ‚Äì Dec 2024) - BSc in Computer Science (Cybersecurity & CPS)\nSingapore Polytechnic (Mar 2018 ‚Äì Apr 2021) - Diploma in Computer Engineering\n\nCertifications: AWS Certified Solutions Architect\nProgramming Skills: JavaScript, R Coding, Python, ReactJS, Java, C/C++\nCybersecurity Skills: OWASP ZAP, SQL Injection Testing, IAM, Risk Management, Threat Intelligence\n\n\n\n\nThis website is structured into several sections to help visitors and myself find useful solutions:\n- Cyber Defense & Threat Intelligence: Articles and resources on security best practices, penetration testing, and risk management.\n- Mastering Code & Development: Code snippets, tutorials, and solutions for common programming challenges.\n- Cloud Computing & Scalability: Insights into AWS, serverless computing, and cloud security.\n- GitHub Mastery & DevOps: Guides on version control, GitHub Actions, and repository management.\n- AI & Machine Learning Innovations: Machine learning, deep learning, and AI-related projects.\n\n\n\n\nAWS Security Automation (View Project) - Implemented AWS Lambda, API Gateway, and Security Hub for real-time security analysis.\nInsider Threat Detection (View Project) - Built ML-based risk assessment using TensorFlow and Scikit Learn.\nIoT Smart System (View Project) - Designed IoT applications with AWS cloud connectivity.\n\n\n\n\n\nDeep Learning Week Hackathon (2022) - Led AI solution for real-time pedestrian and vehicle detection.\nLyve Cloud Hackathon (2022) - Developed cloud-based media streaming server.\n\n\n\n\nFeel free to connect with me on:\n- üìß Email: haiyang.xu.2021@scis.smu.edu.sg\n- üîó LinkedIn\n- üêô GitHub\n- üìÑ Download My Resume\n\n\nIn the AI era, cybersecurity professionals are the guardians of innovation, ensuring that technological advancements remain secure and trustworthy."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Welcome to Haiyang‚Äôs Tech Portfolio",
    "section": "",
    "text": "Education:\n\nSingapore Management University (Aug 2021 ‚Äì Dec 2024) - BSc in Computer Science (Cybersecurity & CPS)\nSingapore Polytechnic (Mar 2018 ‚Äì Apr 2021) - Diploma in Computer Engineering\n\nCertifications: AWS Certified Solutions Architect\nProgramming Skills: JavaScript, R Coding, Python, ReactJS, Java, C/C++\nCybersecurity Skills: OWASP ZAP, SQL Injection Testing, IAM, Risk Management, Threat Intelligence"
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "Welcome to Haiyang‚Äôs Tech Portfolio",
    "section": "",
    "text": "AWS Security Automation (View Project) - Implemented AWS Lambda, API Gateway, and Security Hub for real-time security analysis.\nInsider Threat Detection (View Project) - Built ML-based risk assessment using TensorFlow and Scikit Learn.\nIoT Smart System (View Project) - Designed IoT applications with AWS cloud connectivity."
  },
  {
    "objectID": "index.html#latest-blog-posts",
    "href": "index.html#latest-blog-posts",
    "title": "Welcome to My Tech Portfolio",
    "section": "",
    "text": "Understanding Zero Trust Security Model (Read More)\nDeploying Serverless Applications with AWS Lambda (Read More)\nIoT Device Hardening: Best Practices (Read More)"
  },
  {
    "objectID": "index.html#hackathons-achievements",
    "href": "index.html#hackathons-achievements",
    "title": "Welcome to Haiyang‚Äôs Tech Portfolio",
    "section": "",
    "text": "Deep Learning Week Hackathon (2022) - Led AI solution for real-time pedestrian and vehicle detection.\nLyve Cloud Hackathon (2022) - Developed cloud-based media streaming server."
  },
  {
    "objectID": "index.html#get-in-touch",
    "href": "index.html#get-in-touch",
    "title": "Welcome to Haiyang‚Äôs Tech Portfolio",
    "section": "",
    "text": "Feel free to connect with me on:\n- üìß Email: haiyang.xu.2021@scis.smu.edu.sg\n- üîó LinkedIn\n- üêô GitHub\n- üìÑ Download My Resume\n\n\nIn the AI era, cybersecurity professionals are the guardians of innovation, ensuring that technological advancements remain secure and trustworthy."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#explore-topics",
    "href": "index.html#explore-topics",
    "title": "Welcome to Haiyang‚Äôs Tech Portfolio",
    "section": "",
    "text": "This website is structured into several sections to help visitors and myself find useful solutions:\n- Cyber Defense & Threat Intelligence: Articles and resources on security best practices, penetration testing, and risk management.\n- Mastering Code & Development: Code snippets, tutorials, and solutions for common programming challenges.\n- Cloud Computing & Scalability: Insights into AWS, serverless computing, and cloud security.\n- GitHub Mastery & DevOps: Guides on version control, GitHub Actions, and repository management.\n- AI & Machine Learning Innovations: Machine learning, deep learning, and AI-related projects."
  },
  {
    "objectID": "ai.html",
    "href": "ai.html",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Below is a list of 20 commands (prompt techniques) you can use with ChatGPT to improve your research and work productivity. Each command includes a brief explanation and a copyable prompt.\n\n\nPrompt:\nSummarize the following text: [insert text]  \nExplanation: Quickly distills lengthy articles or reports into a concise summary.\n\n\n\nPrompt:\nExplain [concept] like I‚Äôm 5.  \nExplanation: Breaks down complex topics into simple, easy-to-understand language.\n\n\n\nPrompt:\nAct as a [research assistant/expert in renewable energy/etc.].  \nExplanation: Guides ChatGPT to respond in the tone and style of a specified expert.\n\n\n\nPrompt:\nGenerate an outline for a report on [topic].  \nExplanation: Creates a structured blueprint for projects, articles, or presentations.\n\n\n\nPrompt:\nList the pros and cons of [subject].  \nExplanation: Helps evaluate options by comparing benefits and drawbacks.\n\n\n\nPrompt:\nCompare [option A] and [option B].  \nExplanation: Provides a side-by-side comparison for decision-making.\n\n\n\nPrompt:\nTranslate the following text to [language]: [insert text].  \nExplanation: Converts text into different languages, aiding localization.\n\n\n\nPrompt:\nRewrite this text in simpler language: [insert text].  \nExplanation: Makes technical or dense content more accessible.\n\n\n\nPrompt:\nBrainstorm creative ideas for [project/topic].  \nExplanation: Generates innovative ideas to overcome creative blocks.\n\n\n\nPrompt:\nGive me a step-by-step guide on how to [task].  \nExplanation: Breaks down tasks into clear, actionable steps.\n\n\n\nPrompt:\nGive me synonyms for [word].  \nExplanation: Helps find alternative words for better phrasing.\n\n\n\nPrompt:\nExplain this code: [insert code].  \nExplanation: Breaks down and explains code snippets in simple terms.\n\n\n\nPrompt:\nFind and fix errors in this code: [insert code].  \nExplanation: Identifies and corrects errors in programming code.\n\n\n\nPrompt:\nGenerate a sample paragraph about [topic].  \nExplanation: Creates placeholder or draft text for various needs.\n\n\n\nPrompt:\nCreate a study plan for learning [subject] in [timeframe].  \nExplanation: Helps organize study schedules effectively.\n\n\n\nPrompt:\nExtract the key points from this text: [insert text].  \nExplanation: Pulls out essential details from dense information.\n\n\n\nPrompt:\nCreate a to-do list for [goal/project].  \nExplanation: Structures tasks efficiently for productivity.\n\n\n\nPrompt:\nConvert this text to bullet points: [insert text].  \nExplanation: Reformats text into easier-to-read structures.\n\n\n\nPrompt:\nSummarize the major events of [historical period].  \nExplanation: Provides concise historical overviews.\n\n\n\nPrompt:\nWrite a professional email for [purpose].  \nExplanation: Creates well-structured emails for professional use."
  },
  {
    "objectID": "ai.html#summarize-content",
    "href": "ai.html#summarize-content",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nSummarize the following text: [insert text]  \nExplanation: Quickly distills lengthy articles or reports into a concise summary."
  },
  {
    "objectID": "ai.html#explain-like-im-5-eli5",
    "href": "ai.html#explain-like-im-5-eli5",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nExplain [concept] like I‚Äôm 5.  \nExplanation: Breaks down complex topics into simple, easy-to-understand language."
  },
  {
    "objectID": "ai.html#act-as-role",
    "href": "ai.html#act-as-role",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nAct as a [research assistant/expert in renewable energy/etc.].  \nExplanation: Guides ChatGPT to respond in the tone and style of a specified expert."
  },
  {
    "objectID": "ai.html#generate-an-outline-or-plan",
    "href": "ai.html#generate-an-outline-or-plan",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nGenerate an outline for a report on [topic].  \nExplanation: Creates a structured blueprint for projects, articles, or presentations."
  },
  {
    "objectID": "ai.html#list-pros-and-cons",
    "href": "ai.html#list-pros-and-cons",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nList the pros and cons of [subject].  \nExplanation: Helps evaluate options by comparing benefits and drawbacks."
  },
  {
    "objectID": "ai.html#compare-items",
    "href": "ai.html#compare-items",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nCompare [option A] and [option B].  \nExplanation: Provides a side-by-side comparison for decision-making."
  },
  {
    "objectID": "ai.html#translate-text",
    "href": "ai.html#translate-text",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nTranslate the following text to [language]: [insert text].  \nExplanation: Converts text into different languages, aiding localization."
  },
  {
    "objectID": "ai.html#rewrite-in-simpler-language",
    "href": "ai.html#rewrite-in-simpler-language",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nRewrite this text in simpler language: [insert text].  \nExplanation: Makes technical or dense content more accessible."
  },
  {
    "objectID": "ai.html#brainstorm-ideas",
    "href": "ai.html#brainstorm-ideas",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nBrainstorm creative ideas for [project/topic].  \nExplanation: Generates innovative ideas to overcome creative blocks."
  },
  {
    "objectID": "ai.html#step-by-step-guides",
    "href": "ai.html#step-by-step-guides",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nGive me a step-by-step guide on how to [task].  \nExplanation: Breaks down tasks into clear, actionable steps."
  },
  {
    "objectID": "ai.html#find-alternative-words-thesaurus",
    "href": "ai.html#find-alternative-words-thesaurus",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nGive me synonyms for [word].  \nExplanation: Helps find alternative words for better phrasing."
  },
  {
    "objectID": "ai.html#code-explanation",
    "href": "ai.html#code-explanation",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nExplain this code: [insert code].  \nExplanation: Breaks down and explains code snippets in simple terms."
  },
  {
    "objectID": "ai.html#debug-code",
    "href": "ai.html#debug-code",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nFind and fix errors in this code: [insert code].  \nExplanation: Identifies and corrects errors in programming code."
  },
  {
    "objectID": "ai.html#generate-sample-text",
    "href": "ai.html#generate-sample-text",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nGenerate a sample paragraph about [topic].  \nExplanation: Creates placeholder or draft text for various needs."
  },
  {
    "objectID": "ai.html#create-a-study-plan",
    "href": "ai.html#create-a-study-plan",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nCreate a study plan for learning [subject] in [timeframe].  \nExplanation: Helps organize study schedules effectively."
  },
  {
    "objectID": "ai.html#extract-key-information",
    "href": "ai.html#extract-key-information",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nExtract the key points from this text: [insert text].  \nExplanation: Pulls out essential details from dense information."
  },
  {
    "objectID": "ai.html#generate-a-to-do-list",
    "href": "ai.html#generate-a-to-do-list",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nCreate a to-do list for [goal/project].  \nExplanation: Structures tasks efficiently for productivity."
  },
  {
    "objectID": "ai.html#convert-text-format",
    "href": "ai.html#convert-text-format",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nConvert this text to bullet points: [insert text].  \nExplanation: Reformats text into easier-to-read structures."
  },
  {
    "objectID": "ai.html#historical-events-summary",
    "href": "ai.html#historical-events-summary",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nSummarize the major events of [historical period].  \nExplanation: Provides concise historical overviews."
  },
  {
    "objectID": "ai.html#generate-email-templates",
    "href": "ai.html#generate-email-templates",
    "title": "20 Useful ChatGPT Commands for Research & Productivity",
    "section": "",
    "text": "Prompt:\nWrite a professional email for [purpose].  \nExplanation: Creates well-structured emails for professional use."
  },
  {
    "objectID": "github.html",
    "href": "github.html",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git clone &lt;repository_url&gt;\nExplanation: This command creates a local copy of the remote repository. Replace &lt;repository_url&gt; with the actual URL of the repository you want to clone (e.g., https://github.com/user/repo.git).\n\n\n\ngit status\nExplanation: This command shows the current status of your working directory and staging area, including changes that are staged for commit and those that are not.\n\n\n\ngit add &lt;file_or_directory&gt;\nExplanation: This command stages changes for the next commit. Replace &lt;file_or_directory&gt; with the file or directory you want to stage. To stage all changes, use git add ..\n\n\n\ngit commit -m \"Your commit message\"\nExplanation: This command commits the staged changes to the repository with a message describing the changes. Replace \"Your commit message\" with a brief but descriptive message.\n\n\n\ngit log\nExplanation: This command shows the commit history, listing all commits made in the repository, along with their details such as author, date, and commit message.\n\n\n\ngit push origin &lt;branch_name&gt;\nExplanation: This command uploads your local commits to the remote repository. Replace &lt;branch_name&gt; with the branch you‚Äôre working on (e.g., main or develop).\n\n\n\ngit pull origin &lt;branch_name&gt;\nExplanation: This command fetches and merges changes from the remote repository into your local repository. Replace &lt;branch_name&gt; with the name of the branch you want to pull from (usually main).\n\n\n\ngit checkout -b &lt;new_branch_name&gt;\nExplanation: This command creates and switches to a new branch. Replace &lt;new_branch_name&gt; with the name you want for the new branch.\n\n\n\ngit checkout &lt;branch_name&gt;\nExplanation: This command switches to an existing branch. Replace &lt;branch_name&gt; with the name of the branch you want to switch to.\n\n\n\ngit merge &lt;branch_name&gt;\nExplanation: This command merges changes from another branch into your current branch. Replace &lt;branch_name&gt; with the branch you want to merge.\n\n\n\ngit branch -d &lt;branch_name&gt;\nExplanation: This command deletes a local branch. Replace &lt;branch_name&gt; with the name of the branch you want to delete.\n\n\n\ngit remote -v\nExplanation: This command shows the URLs of the remote repositories associated with your local repository.\n\n\n\ngit remote add origin &lt;repository_url&gt;\nExplanation: This command adds a remote repository to your local repository. Replace &lt;repository_url&gt; with the actual URL of the remote repository.\n\n\n\ngit reset --hard\nExplanation: This command resets your working directory and staging area to the last commit, discarding any uncommitted changes.\n\n\n\ngit diff\nExplanation: This command shows the differences between the working directory and the staging area, or between two commits.\n\n\n\ngit stash\nExplanation: This command temporarily saves your changes, allowing you to work on something else without committing those changes.\n\n\n\ngit tag &lt;tag_name&gt;\nExplanation: This command creates a tag for a specific commit. Replace &lt;tag_name&gt; with the name of the tag (e.g., v1.0).\n\n\n\ngit push origin &lt;tag_name&gt;\nExplanation: This command pushes the tag to the remote repository.\n\n\n\ngit push origin --delete &lt;branch_name&gt;\nExplanation: This command deletes a branch from the remote repository.\n\n\n\ngh issue list\nExplanation: This command lists open issues in a GitHub repository (requires the GitHub CLI). You can filter, view, and manage issues directly from the terminal.\n\n\n\ngh issue create\nExplanation: This command creates a new GitHub issue (requires the GitHub CLI). Follow the prompts to enter the issue title, description, and labels."
  },
  {
    "objectID": "github.html#cloning-a-repository",
    "href": "github.html#cloning-a-repository",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git clone &lt;repository_url&gt;\nExplanation: This command creates a local copy of the remote repository. Replace &lt;repository_url&gt; with the actual URL of the repository you want to clone (e.g., https://github.com/user/repo.git)."
  },
  {
    "objectID": "github.html#checking-repository-status",
    "href": "github.html#checking-repository-status",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git status\nExplanation: This command shows the current status of your working directory and staging area, including changes that are staged for commit and those that are not."
  },
  {
    "objectID": "github.html#adding-changes-to-staging-area",
    "href": "github.html#adding-changes-to-staging-area",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git add &lt;file_or_directory&gt;\nExplanation: This command stages changes for the next commit. Replace &lt;file_or_directory&gt; with the file or directory you want to stage. To stage all changes, use git add .."
  },
  {
    "objectID": "github.html#committing-changes",
    "href": "github.html#committing-changes",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git commit -m \"Your commit message\"\nExplanation: This command commits the staged changes to the repository with a message describing the changes. Replace \"Your commit message\" with a brief but descriptive message."
  },
  {
    "objectID": "github.html#viewing-commit-history",
    "href": "github.html#viewing-commit-history",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git log\nExplanation: This command shows the commit history, listing all commits made in the repository, along with their details such as author, date, and commit message."
  },
  {
    "objectID": "github.html#pushing-changes-to-a-remote-repository",
    "href": "github.html#pushing-changes-to-a-remote-repository",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git push origin &lt;branch_name&gt;\nExplanation: This command uploads your local commits to the remote repository. Replace &lt;branch_name&gt; with the branch you‚Äôre working on (e.g., main or develop)."
  },
  {
    "objectID": "github.html#pulling-latest-changes-from-remote",
    "href": "github.html#pulling-latest-changes-from-remote",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git pull origin &lt;branch_name&gt;\nExplanation: This command fetches and merges changes from the remote repository into your local repository. Replace &lt;branch_name&gt; with the name of the branch you want to pull from (usually main)."
  },
  {
    "objectID": "github.html#creating-a-new-branch",
    "href": "github.html#creating-a-new-branch",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git checkout -b &lt;new_branch_name&gt;\nExplanation: This command creates and switches to a new branch. Replace &lt;new_branch_name&gt; with the name you want for the new branch."
  },
  {
    "objectID": "github.html#switching-branches",
    "href": "github.html#switching-branches",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git checkout &lt;branch_name&gt;\nExplanation: This command switches to an existing branch. Replace &lt;branch_name&gt; with the name of the branch you want to switch to."
  },
  {
    "objectID": "github.html#merging-a-branch",
    "href": "github.html#merging-a-branch",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git merge &lt;branch_name&gt;\nExplanation: This command merges changes from another branch into your current branch. Replace &lt;branch_name&gt; with the branch you want to merge."
  },
  {
    "objectID": "github.html#deleting-a-branch",
    "href": "github.html#deleting-a-branch",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git branch -d &lt;branch_name&gt;\nExplanation: This command deletes a local branch. Replace &lt;branch_name&gt; with the name of the branch you want to delete."
  },
  {
    "objectID": "github.html#viewing-remote-repositories",
    "href": "github.html#viewing-remote-repositories",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git remote -v\nExplanation: This command shows the URLs of the remote repositories associated with your local repository."
  },
  {
    "objectID": "github.html#adding-a-remote-repository",
    "href": "github.html#adding-a-remote-repository",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git remote add origin &lt;repository_url&gt;\nExplanation: This command adds a remote repository to your local repository. Replace &lt;repository_url&gt; with the actual URL of the remote repository."
  },
  {
    "objectID": "github.html#resetting-changes",
    "href": "github.html#resetting-changes",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git reset --hard\nExplanation: This command resets your working directory and staging area to the last commit, discarding any uncommitted changes."
  },
  {
    "objectID": "github.html#viewing-differences-between-versions",
    "href": "github.html#viewing-differences-between-versions",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git diff\nExplanation: This command shows the differences between the working directory and the staging area, or between two commits."
  },
  {
    "objectID": "github.html#stashing-changes",
    "href": "github.html#stashing-changes",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git stash\nExplanation: This command temporarily saves your changes, allowing you to work on something else without committing those changes."
  },
  {
    "objectID": "github.html#creating-a-tag",
    "href": "github.html#creating-a-tag",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git tag &lt;tag_name&gt;\nExplanation: This command creates a tag for a specific commit. Replace &lt;tag_name&gt; with the name of the tag (e.g., v1.0)."
  },
  {
    "objectID": "github.html#pushing-tags-to-remote",
    "href": "github.html#pushing-tags-to-remote",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git push origin &lt;tag_name&gt;\nExplanation: This command pushes the tag to the remote repository."
  },
  {
    "objectID": "github.html#deleting-a-remote-branch",
    "href": "github.html#deleting-a-remote-branch",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "git push origin --delete &lt;branch_name&gt;\nExplanation: This command deletes a branch from the remote repository."
  },
  {
    "objectID": "github.html#viewing-github-issues",
    "href": "github.html#viewing-github-issues",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "gh issue list\nExplanation: This command lists open issues in a GitHub repository (requires the GitHub CLI). You can filter, view, and manage issues directly from the terminal."
  },
  {
    "objectID": "github.html#creating-a-github-issue",
    "href": "github.html#creating-a-github-issue",
    "title": "Useful GitHub Commands",
    "section": "",
    "text": "gh issue create\nExplanation: This command creates a new GitHub issue (requires the GitHub CLI). Follow the prompts to enter the issue title, description, and labels."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Me",
    "section": "",
    "text": "Let‚Äôs Connect!\n\nEmail: üìß haiyang.xu.2021@scis.smu.edu.sg\nPhone: üì± +65 8090 8720\nLinkedIn: üîó Haiyang Xu\nResume: üìÑ Download my Resume"
  },
  {
    "objectID": "cloud.html",
    "href": "cloud.html",
    "title": "AWS Solution Architect Summary",
    "section": "",
    "text": "Number of Edge Locations &gt; Number of Availability zones &gt; Number of regions\n\nA region is a physical location spread across globe to host your data to reduce latency. In each region there will be at least two availability zones.\nAn availability zone is a datacenter that does not need to be separated by multiple kilometers physically but by meters with in a physical compound which are completely isolated from each other failure such as power, network in a given AZ.\nAn edge location is where end users access services located at AWS. A site that CloudFront uses to cache copies of your content for faster delivery to users at any location. Edge locations serve requests for CloudFront and Route 53. Requests going to either one of these services will be routed to the nearest edge location automatically."
  },
  {
    "objectID": "cloud.html#the-basics-regions-availability-zones-edge-locations",
    "href": "cloud.html#the-basics-regions-availability-zones-edge-locations",
    "title": "AWS Solution Architect Summary",
    "section": "",
    "text": "Number of Edge Locations &gt; Number of Availability zones &gt; Number of regions\n\nA region is a physical location spread across globe to host your data to reduce latency. In each region there will be at least two availability zones.\nAn availability zone is a datacenter that does not need to be separated by multiple kilometers physically but by meters with in a physical compound which are completely isolated from each other failure such as power, network in a given AZ.\nAn edge location is where end users access services located at AWS. A site that CloudFront uses to cache copies of your content for faster delivery to users at any location. Edge locations serve requests for CloudFront and Route 53. Requests going to either one of these services will be routed to the nearest edge location automatically."
  },
  {
    "objectID": "cloud.html#how-to-create-a-role",
    "href": "cloud.html#how-to-create-a-role",
    "title": "AWS Solution Architect Summary",
    "section": "How to create a Role",
    "text": "How to create a Role\n\nIAM &gt; Roles &gt; Create Role\nChoose the service that will use this role\nAttach policies\n\n\nRoles are more secure than storing your access key and secret access key on individual EC2 instances.\nRoles are easier to manage.\nRoles can be assigned to an EC2 instance after it is created using both the console and command line.\nRoles are universal - you can use them in any region."
  },
  {
    "objectID": "cloud.html#create-a-billing-alarm",
    "href": "cloud.html#create-a-billing-alarm",
    "title": "AWS Solution Architect Summary",
    "section": "Create a billing alarm",
    "text": "Create a billing alarm\n\nGo to My Account &gt; Billing Dashboard &gt; Billing Preferences\nEnable Receive Billing Alarts\nThen, go to Services &gt; Cloud Watch &gt; Billing\nFill the Billing alarm section (with the amount of dollars)"
  },
  {
    "objectID": "cloud.html#storage-classes",
    "href": "cloud.html#storage-classes",
    "title": "AWS Solution Architect Summary",
    "section": "Storage Classes",
    "text": "Storage Classes\n\nS3 Standard\nS3 IA: Infrequently Accessed but requires rapid access. Lower fee then standard, but you‚Äôre charged a retrieval fee.\nS3 One Zone - IA: Infrequently Accessed and do not require the multiple availability zones. Lowest option.\nS3 Intelligent Tiering: Use machine learning to configure the objects around storage classes to the most cost-effective option.\nS3 Glacier: For data archiving. Secure, durable, low-cost storage. Retrieval times configurable from minutes to hours.\nS3 Glacier Deep Archive: Same as above but it allows retrieval times of 12 hours."
  },
  {
    "objectID": "cloud.html#transfer-acceleration",
    "href": "cloud.html#transfer-acceleration",
    "title": "AWS Solution Architect Summary",
    "section": "Transfer Acceleration",
    "text": "Transfer Acceleration\nAmazon S3 Transfer Acceleration enables fast, easy, and secure transfer of files over long distances between your end users and an S3 bucket. It takes advantage of Amazon CloudFront‚Äôs globally distributed edge locations: as the data arrives at an edge location, data is routed to Amazon S3 over an optimized network path."
  },
  {
    "objectID": "cloud.html#security",
    "href": "cloud.html#security",
    "title": "AWS Solution Architect Summary",
    "section": "Security",
    "text": "Security\nWe can configure S3 to log who is accessing the objects. Secure your data using access control lists or using bucket policies.\nWe can encrypt by:\n\nEncryption In Transit: SSL/TLS\nEncryption At Rest (Server Side) via (1) S3 Managed Keys - SSE-S3, (2) AWS Key Management Service - SS3-KMS, or (3) Server Side Encryption with customer - SS3-C (you provide the keys).\nClient Side Encryption"
  },
  {
    "objectID": "cloud.html#cross-region-replication",
    "href": "cloud.html#cross-region-replication",
    "title": "AWS Solution Architect Summary",
    "section": "Cross Region Replication",
    "text": "Cross Region Replication\nIn order to replicate your data in different regions.\n\nCreate bucket\nGo to Management and Replication\nEnable versioning (it must be enabled in both source and destination)\nSet Source and Destination\nConfiguration options: select/create the role\n\nFiles in an existing bucket and delete markers (or versions) are not replicated automatically. It only works for new files."
  },
  {
    "objectID": "cloud.html#pricing",
    "href": "cloud.html#pricing",
    "title": "AWS Solution Architect Summary",
    "section": "Pricing",
    "text": "Pricing\n\nBy Storage class\nBy Requests\nBy Storage Management Pricing\nBy Data Transfer Pricing\nBy Transfer Acceleration\nBy Cross Region Replication Pricing"
  },
  {
    "objectID": "cloud.html#pricing-1",
    "href": "cloud.html#pricing-1",
    "title": "AWS Solution Architect Summary",
    "section": "Pricing",
    "text": "Pricing\n\n\n\n\n\n\n\n\nType\nDescription\nUse Cases\n\n\n\n\nOn Demand\nFixed rate by the hour (or by the second)\nLow cost and flexibility. (1) Applications with short term, spiky or unpredictable workloads that cannot be interrupted. (2) Applications being developed or tested for the first time.\n\n\nReserved: Standard or Convertible or Scheduled\nProvides you with a capacity reservation, and offer a significant discount on the hourly charge for an instance. Contract terms are 1 year or 3 years.\n(1) Applications with steady state or predictable usage. (2) Applications that require reserved capacity. (3) Users able to male upfront payments to reduce their total computing costs even further.\n\n\nSpot\nEnables you to bid whatever price you want for instance capacity, providing for even greater savings if your applications have flexible start and end times.\n(1) Applications that have flexible start and end times. (2) Applications that are only feasible at very low compute prices. (3) Users with urgent computing needs for large amounts of additional capacity.\n\n\nDedicated hosts\nPhysical EC2 server dedicated. It can help you reduce costs by allowing you to use your existing server-bound software licenses. It can be purchased On-Demand (hourly) or as a reservation for up to 70% off the On-Demand price.\n(1) Useful for regulatory requirements that may not support multi-tenant virtualization. (2) Great for licensing which does not support multi-tenancy or cloud deployments."
  },
  {
    "objectID": "cloud.html#instance-types",
    "href": "cloud.html#instance-types",
    "title": "AWS Solution Architect Summary",
    "section": "Instance Types",
    "text": "Instance Types\n\nThis won‚Äôt be part of the exam. The summary is:\n\nF: For FPGA\nI: For IOPS\nG: Graphics\nH: High Disk Throughput\nT: Cheap general purpose\nD: For Density\nR: For RAM\nM: Main choice for general purpose apps\nC: For Compute\nP: Graphics (think Pics)\nX: Extreme Memory\nZ: Extreme Memory and CPU\nA: ARM-Based workloads\nU: Bare Metal"
  },
  {
    "objectID": "cloud.html#placement-groups",
    "href": "cloud.html#placement-groups",
    "title": "AWS Solution Architect Summary",
    "section": "Placement Groups",
    "text": "Placement Groups\nThe name of placement groups must be unique within your AWS account. Only certain types of instances can be launched in a placement group: compute optimized, GPU, memory optimized and storage optimized. We can‚Äôt move existing instances into a placement group (they must be selected when are being created).\n\nClustered Placement Group: group instances within a single availability zone. This is recommended for applications that need low network latency, high network throughput or both. Only certain instances can be launched in this mode.\nSpread Placement Group: This is the opposite. Instances that are each placed on distinct underlying hardware. This is recommended for applications that have a small number of critical instances that should be kept separate from each other."
  },
  {
    "objectID": "cloud.html#ebs-backed-versus-instance-store",
    "href": "cloud.html#ebs-backed-versus-instance-store",
    "title": "AWS Solution Architect Summary",
    "section": "EBS-Backed Versus Instance Store",
    "text": "EBS-Backed Versus Instance Store\nAn instance store provides temporary block-level storage for your instance. Instance Store Volumes are sometimes called Ephemeral Storage. This storage is located on disks that are physically attached to the host computer. Instance store is ideal for temporary storage of information that changes frequently, such as buffers, caches, scratch data, and other temporary content, or for data that is replicated across a fleet of instances, such as a load-balanced pool of web servers.\n\nInstance store volumes cannot be stopped. If the underlying host fails, you will lose your data.\n\nAn ‚ÄúEBS-backed‚Äù instance is an EC2 instance which uses an EBS volume as it‚Äôs root device. EBS volumes are redundant, ‚Äúvirtual‚Äù drives, which are not tied to any particular hardware, however they are restricted to a particular EC2 availability zone. This means that an EBS volume can move from one piece of hardware to another within the same availability zone. You can think of EBS volumes as a kind of Network Attached Storage.\nIf the virtual machine‚Äôs hardware fails, the EBS volume can simply be moved to another virtual machine and re-launched. In theory, you won‚Äôt lose any data.\nAnother benefit is that EBS volumes can easily be backed up and duplicated. So you can take easy backup snapshots of your volumes, create new volumes and launch new EC2 instances based on those duplicate volumes.\n\nEBS backed instances can be stopped. You won‚Äôt lose the data on this instance if it is stopped.\nBy default, both root volumes will be deleted on termination. However, with EBS volumes, you can tell AWS to keep the device volume."
  },
  {
    "objectID": "cloud.html#backups",
    "href": "cloud.html#backups",
    "title": "AWS Solution Architect Summary",
    "section": "Backups",
    "text": "Backups\nAutomated backups allow you to recover your database to any point in time within a ‚Äúretention period‚Äù. The retention period can be between one and 35 days. Automated backups will take a full daily snapshot and will also store transaction logs throughout the day. When you do a recovery, AWS will first choose the most recent daily back up, and then apply transaction logs relevant to that day. This allows you to do a point in time recovery down to a second, within the retention period.\nAutomated backups are enabled by default. The backup data is stored in S3 and you get free storage space equal to the size of your database. So if you have and RDS instance of 10GB, you will get 10GB worth of storage.\nBackups are taken within a defined window, storage I/O may be suspended while your data is being backed up and you may experience elevated latency."
  },
  {
    "objectID": "cloud.html#snapshots",
    "href": "cloud.html#snapshots",
    "title": "AWS Solution Architect Summary",
    "section": "Snapshots",
    "text": "Snapshots\nDatabase snapshots are done manually. They are stored even after you delete the original RDS instance, unlike automated backups."
  },
  {
    "objectID": "cloud.html#restoring",
    "href": "cloud.html#restoring",
    "title": "AWS Solution Architect Summary",
    "section": "Restoring",
    "text": "Restoring\nWhenever you restore either a backup or a snapshot, the restored version of the database will be a new RDS instance with a new DNS endpoint."
  },
  {
    "objectID": "cloud.html#aurora",
    "href": "cloud.html#aurora",
    "title": "AWS Solution Architect Summary",
    "section": "Aurora",
    "text": "Aurora\nAmazon Aurora is a MySQL-compatible relational database that combines the speed and availability of high-end commercial databases with the simplicity and cost-effectiveness of open source database. It provides up to five times better performance than MySQL at better price for similar performance.\n\nStart with 10GB, scales in 10GB increments to 64TB (storage autoscaling).\nCompute resources can scale up to 32vCPUs and 244GB of Memory. It is designed to transparently handle the loss of up to two copies of data without affecting database write availability and up to three copies without affecting read availability.\nIt always maintain 2 copies in each availability zone with a minimum of 3 availability zones. 6 copies of your data.\nAurora storage is also self-healing. Data blocks and disks are continuously scanned for errors and automatically repaired.\nBackups are always enabled and do not impact on database performance.\nWe can take snapshots and share them with other AWS accounts.\n2 types of replicas available: aurora replicas and MySQL replicas. Automated failover is only available with Aurora replicas."
  },
  {
    "objectID": "cloud.html#register-a-new-domain",
    "href": "cloud.html#register-a-new-domain",
    "title": "AWS Solution Architect Summary",
    "section": "Register a new domain:",
    "text": "Register a new domain:\n\nGo to Route53 &gt; Register Domain\nSearch for your domain\nFill out the registrant contact\nPurchase your new domain\n\nIt takes some time to register the domain‚Ä¶ between a few hours up to 3 days."
  },
  {
    "objectID": "cloud.html#routing-policies",
    "href": "cloud.html#routing-policies",
    "title": "AWS Solution Architect Summary",
    "section": "Routing Policies",
    "text": "Routing Policies\nFirst, let‚Äôs see how to configure routing policies:\n\nGo to Route53 &gt; Your domain\nCreate Record Set\nSelect the DNS record type.\n\nAlso, we can set health checks on individual record sets. If a record set fails a health check it will be removed from Route53 until it passes the health check. We can set SNS notifications to alert you if health check is failing.\n\nSimple Routing Policy\n\nOne record with multiple IP addresses. If you specify multiple values in a record, Route53 returns all values to the user in a random order.\n\nWeighted Routing Policy\n\nAllows you split your traffic based on different weights assigned. For example, you can set 10% of your traffict to go to US-EAST-1 and 90% to EU-WEST-1.\n\nLetancy Routing Policy\n\nAllows you to route your traffic based on the lowest network latency for your end user (ie which region will give them the fastest response time).\nTo use latency-based routing, we need to create a latency resource record set for EC2 or ELB resource in each region that hosts your website.\n\nFallover Routing Policy\n\nThis is used when you want to create an active/passive set up. For example, you may want your primary site to be in EU-WEST-2 and your secondary DR Site in AP-SOUTHEAST-2. Route53 will monitor the health or your primary site using health checks.\n\nGeolocation Routing Policy\n\nDepending on our final users location.\n\nGeoproximity Routing Policy (Traffict Flow Only)\n\nGeoproximity routing lets Route53 route traffic to your resources based on the geographic location of your users and your resources. You can also optionally choose to route more traffic or less to a given resource by specifying a value, known as a bias. A bias expands or shrinks the size of the geographic region from which traffic ir routed to a resource.\n\nMultivalue Answer Policy\n\nIt lets you configure Route53 to return multiple values, such as IP addresses for your web servers, in response to DNS queries. You can specify multiple values for almost any record, but multivalue answer routing also lets you check the health of each resource, so Route53 returns only values for healthy resources.\nSimilar to simple routing but with health checks on each record set."
  },
  {
    "objectID": "cloud.html#default-vpc-vs-custom-vpc",
    "href": "cloud.html#default-vpc-vs-custom-vpc",
    "title": "AWS Solution Architect Summary",
    "section": "Default VPC vs Custom VPC",
    "text": "Default VPC vs Custom VPC\n\nDefault VPC is user friendly, allowing you to immediately deploy instances.\nAll Subnets in default VPC have a route out to the internet.\nEach EC2 instance has both a public and private IP address."
  },
  {
    "objectID": "cloud.html#vpc-peering-vpc-vpc",
    "href": "cloud.html#vpc-peering-vpc-vpc",
    "title": "AWS Solution Architect Summary",
    "section": "VPC Peering (VPC <‚Äì> VPC)",
    "text": "VPC Peering (VPC &lt;‚Äì&gt; VPC)\nAllows you to connect one VPC with another via a direct network route using private IP addresses. Instances behave as if they were on the same private network. We can peer VPC‚Äôs with other AWS accounts as well as with other VPCs in the same account. Peering is a star configuration: 1 central VPC peers with 4 others: no transitive peering!!"
  },
  {
    "objectID": "cloud.html#how-to",
    "href": "cloud.html#how-to",
    "title": "AWS Solution Architect Summary",
    "section": "How-To",
    "text": "How-To\n\nGo To VPC service &gt; Your VPCs &gt; Create VPC\nFill IPv4 CIDR block and tenancy and click on create.\n\nNo subnets and internet gateways have been created at this moment. Route table, network ACLs and security groups have been created. Security groups can‚Äôt span VPCs.\n\nGo to Subnets -&gt; Create subnet\nName it, select our VPC, the availability zone and the IPv4 CIDR block. Finally, click on create.\n\nBy default, no subnet has public IP. In order to do this, select the subnet and click on actions and make it auto apply public IP. Amazon always reserve 5 IP addresses with your subnets.\n\nGo to Internet Gateways -&gt; Create internet gateway\nName it and click on create.\nSelect it and with actions, attach the internet gateway to the VPC. (Only ONLY VPC can be attached to ONE internet gateway)\n\nAt the moment, all our VPC are public because our routes allow it. Let‚Äôs fix this:\n\nGo to Route Tables -&gt; select our route table and select ‚ÄúRoutes‚Äù\nEdit routes\nFill destination (any IP) with target internet gateway\nGo to Subnet Associations\nEdit subnet associations in order to select the subnet that needs to be public.\n\nNow, we can‚Äôt ssh-access to our private ec2 instance from our public subnet.\n\nGo to EC2 &gt; Security Groups -&gt; Create Security Group\nSelect our VPC, type ‚ÄúAll ICMP‚Äù (protocol ICMP) and the source the public subnet.\nSelect our VPC, type ‚ÄúSSH‚Äù and the source the private subnet.\nChange the security group of our ec2 instance."
  },
  {
    "objectID": "cloud.html#how-to-connect-to-our-instances",
    "href": "cloud.html#how-to-connect-to-our-instances",
    "title": "AWS Solution Architect Summary",
    "section": "How to connect to our instances?",
    "text": "How to connect to our instances?\nIn order to install/update software, we can use the Network Address Translation:\n\nNetwork Address Translation (NAT): via NAT instance of via NAT gateway\nThis will allow private instances to download software (via yum) without becaming publicly exposed. For this, we need to make our private instance a NAT instance. This NAT instance will communicate with a NAT Gateway, so we need to change the source/destination check in order to replace the ‚Äúinternet‚Äù gateway by our NAT gateway‚Äù.\nThen, we need to go to VPC &gt; Create NAT Gateway &gt; Create. Then, select the public subnet and create a elastic IP address. Finally, we need to go to VPC &gt; Routes and add a route to route all the IP addresses to a NAT gateway.\nAbout NAT instance:\n\nNAT instances must be in a public subnet.\nThere must be a route out of the private subnet to the NAT instance, in order for this to work.\nThe amount of traffict that NAT instances can support depends on the instance size. If you are bottlenecking, increase the instance size.\nYou can create high availability using autoscaling groups, multiple subnets in different AZs, and a script to automate failover.\n\nAbout NAT gateway:\n\nNAT Gateways are redundant inside the Availability Zone. One NAT gateway per availability zone.\nPreferred by the enterprise.\nStarts at 5Gbps and scales currently up to 45 Gbps.\nNo need to patch\nNot associated with security groups.\nAutomatically assigned a public IP address.\nNo needed to disable the source/destination check.\nIn order to have high availability, we should create a NAT gateway in each availability zone.\n\n\n\nBastion\n\nA Bastion is used to securely administer EC2 instances (using ssh or RDP. Bastions are called Jump Boxes in Australia).\nWe cannot use a NAT Gateway as a Bastion host.\n\n\n\nDirect Connect\nAWS Direct Connect is a cloud service solution that makes it easy to establish a dedicated network connection from your premises to AWS. Therefore, we can establish private connectivity between AWS and your datacenter, office, or colocation environment, which in many cases can reduce your network costs, increase bandwidth throughput and provide a more consistent network experience than Internet-based connections.\n\n\nVPC Endpoint\nAn interface endpoint is an elastic network interface with a private IP address that serves as an entry point for traffic destined to a supported service.\nA VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection or AWS Direct Connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not have the Amazon network.\nEndpoints are virtual devices. They are horizontally scaled, redundant, and highly available VPC components that allow communication between instances in your VPC and services without imposing availability risks or bandwidth constrains on your network traffic.\n\nThere are two types: interface and gateway\nCurrently, gateway endpoints support S3 and DynamoDB"
  },
  {
    "objectID": "cloud.html#network-access-control-lists-acl",
    "href": "cloud.html#network-access-control-lists-acl",
    "title": "AWS Solution Architect Summary",
    "section": "Network Access Control Lists (ACL)",
    "text": "Network Access Control Lists (ACL)\nThis works like a security group for all(or any) subnets in your VPC. We can add allow/deny rules. The default VPC comes a default network ACL, and by default it allows all outbound and inbound traffic.\nWhen creating a custom network ACLs, by default denies all inbound and outbound traffic until you add rules. Each subnet in your VPC must be associated with a network ACL. If you don‚Äôt explicitly associate a subnet with a network ACL, the subnet is automatically associated with the default network ACL.\nIn order to block IP Addresses, we need to use ACLs, not security groups.\n\nA network ACL can be associated to N subnets, but 1 subnet can only be associated to 1 ACL.\nNetwork ACLs contain a numbered list of rules that is evaluated in order, starting with the lowest numbered rule.\nNetwork ACLs have separate inbound and outbound rules, and each rule can either allow or deny traffic.\nNetwork ACLs are stateless; responses to allowed inbound traffic are subject to the rules for outbound traffic and vice versa."
  },
  {
    "objectID": "cloud.html#vpc-flow-logs",
    "href": "cloud.html#vpc-flow-logs",
    "title": "AWS Solution Architect Summary",
    "section": "VPC Flow Logs",
    "text": "VPC Flow Logs\nFlow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. Flow log data is stored using Amazon CloudWatch Logs. After you‚Äôve created a flow log, you can view and retrieve its data in Amazon CloudWatch Logs.\n\nThere are three levels of abstraction: VPC, subnet and network access level.\nYou cannot enable flow logs for VPCs that are peered with your VPC unless the peer VPC is in your account.\nYou cannot tag a flow log.\nAfter you‚Äôve created a flow log, you cannot change its configuration; for example, you can‚Äôt associate a different IAM role with the flow log.\nNot ALL IP Traffic is monitored: internal traffic done by AWS mostly."
  },
  {
    "objectID": "cloud.html#security-1",
    "href": "cloud.html#security-1",
    "title": "AWS Solution Architect Summary",
    "section": "Security",
    "text": "Security\n\nCross Site Scripting In computing, the same-origin policy is an important concept in the web application security model. Under the policy, a web browser permits scripts contained in a first web page to access data in a second web page, but only if both web pages have the same origin. This will prevent cross-site scripting (XSS) attacks.\nCORS CORS is one way the server at the other end (not the client code in the browser) can relax the same origin policy. Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources (e.g.¬†fonts) on a web page to be requested from another domain outside the domain from which the first resource was served."
  },
  {
    "objectID": "cloud.html#synchronisation",
    "href": "cloud.html#synchronisation",
    "title": "AWS Solution Architect Summary",
    "section": "Synchronisation",
    "text": "Synchronisation\nCognito tracks the association between user identity and the various different devices they sign-in from. In order to provide a seamless user experience for your application, Cognito uses Push Synchronization to push updates and synchronize user data across multiple devices. Cognito uses SNS is to send a notification to all the devices associated with a given user identity whenever data stored in the cloud changes."
  },
  {
    "objectID": "cloud.html#pricing-2",
    "href": "cloud.html#pricing-2",
    "title": "AWS Solution Architect Summary",
    "section": "Pricing",
    "text": "Pricing\nBy number of requests: first 1 million requests are free. Then $0.20 per 1 million requests thereafter. By duration which is calculated from the time your code begins executing until it returns or otherwise terminates, rounded up to the nearest 100ms. The price depends on the amount of memory you allocate to your function. You are charged $0.00001667 for every GB-second used."
  }
]